{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-05-18T08:38:58.773437Z","iopub.status.busy":"2024-05-18T08:38:58.772997Z","iopub.status.idle":"2024-05-18T08:41:53.652392Z","shell.execute_reply":"2024-05-18T08:41:53.651322Z","shell.execute_reply.started":"2024-05-18T08:38:58.773407Z"},"id":"RVOKeezWPsSs","outputId":"aedec320-c1bc-4032-8511-6d6e597e0044","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mCollecting https://gitlab.com/trungtv/vi_spacy/-/raw/master/packages/vi_core_news_lg-3.6.0/dist/vi_core_news_lg-3.6.0.tar.gz\n","  Downloading https://gitlab.com/trungtv/vi_spacy/-/raw/master/packages/vi_core_news_lg-3.6.0/dist/vi_core_news_lg-3.6.0.tar.gz (233.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting spacy<3.7.0,>=3.6.0 (from vi_core_news_lg==3.6.0)\n","  Downloading spacy-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.0.9)\n","Collecting thinc<8.2.0,>=8.1.8 (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0)\n","  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.5.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (69.5.1)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.1.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->vi_core_news_lg==3.6.0) (2.1.3)\n","Downloading spacy-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: vi_core_news_lg\n","  Building wheel for vi_core_news_lg (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for vi_core_news_lg: filename=vi_core_news_lg-3.6.0-py3-none-any.whl size=233275655 sha256=47b699ce354f74e23c25dbd387a74e8ee05ad363d4da6c13fc2c8143b72ab623\n","  Stored in directory: /root/.cache/pip/wheels/bd/c2/22/8dfcbf9006c1be9c5f38dda2e8608eddb2f46c933f174c7581\n","Successfully built vi_core_news_lg\n","Installing collected packages: thinc, spacy, vi_core_news_lg\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.2.2\n","    Uninstalling thinc-8.2.2:\n","      Successfully uninstalled thinc-8.2.2\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.7.4\n","    Uninstalling spacy-3.7.4:\n","      Successfully uninstalled spacy-3.7.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-lg 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.6.1 which is incompatible.\n","en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed spacy-3.6.1 thinc-8.1.12 vi_core_news_lg-3.6.0\n","2024-05-18 08:41:15.479576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-18 08:41:15.479699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-18 08:41:15.609313: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Collecting en-core-web-sm==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.5.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (69.5.1)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n","Installing collected packages: en-core-web-sm\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en-core-web-sm 3.7.1\n","    Uninstalling en-core-web-sm-3.7.1:\n","      Successfully uninstalled en-core-web-sm-3.7.1\n","Successfully installed en-core-web-sm-3.6.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["! pip -q install torchtext==0.6.0\n","! pip -q install -U pip setuptools wheel\n","! pip -q install -U spacy\n","! pip -q install dill\n","! pip -q install pyvi\n","! pip install https://gitlab.com/trungtv/vi_spacy/-/raw/master/packages/vi_core_news_lg-3.6.0/dist/vi_core_news_lg-3.6.0.tar.gz\n","! python -m spacy download en_core_web_sm\n","! pip -q install sacrebleu"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:53.654605Z","iopub.status.busy":"2024-05-18T08:41:53.654302Z","iopub.status.idle":"2024-05-18T08:41:56.071750Z","shell.execute_reply":"2024-05-18T08:41:56.070597Z","shell.execute_reply.started":"2024-05-18T08:41:53.654575Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     /kaggle/working/nltk_data...\n","Archive:  /kaggle/working/nltk_data/corpora/wordnet.zip\n","   creating: /kaggle/working/nltk_data/corpora/wordnet/\n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/lexnames  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/data.verb  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/index.adv  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/adv.exc  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/index.verb  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/cntlist.rev  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/data.adj  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/index.adj  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/LICENSE  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/citation.bib  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/noun.exc  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/verb.exc  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/README  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/index.sense  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/data.noun  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/data.adv  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/index.noun  \n","  inflating: /kaggle/working/nltk_data/corpora/wordnet/adj.exc  \n"]}],"source":["import nltk\n","\n","nltk.download('wordnet', download_dir='/kaggle/working/nltk_data')\n","nltk.data.path.append('/kaggle/working/nltk_data')\n","\n","!unzip \"/kaggle/working/nltk_data/corpora/wordnet.zip\" -d \"/kaggle/working/nltk_data/corpora/\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:56.073451Z","iopub.status.busy":"2024-05-18T08:41:56.073132Z","iopub.status.idle":"2024-05-18T08:41:57.956150Z","shell.execute_reply":"2024-05-18T08:41:57.955274Z","shell.execute_reply.started":"2024-05-18T08:41:56.073419Z"},"id":"8gvN64qvNQIS","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","import math"]},{"cell_type":"markdown","metadata":{"id":"MM1dnT0JKkdk"},"source":["# Embedding Layer with Position Encoding"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:57.958555Z","iopub.status.busy":"2024-05-18T08:41:57.958125Z","iopub.status.idle":"2024-05-18T08:41:57.964407Z","shell.execute_reply":"2024-05-18T08:41:57.963278Z","shell.execute_reply.started":"2024-05-18T08:41:57.958527Z"},"id":"X9da_ZuSNQIW","trusted":true},"outputs":[],"source":["class Embedder(nn.Module):\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.d_model = d_model\n","\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","\n","    def forward(self, x):\n","        return self.embed(x)\n","\n","# Embedder(100, 512)(torch.LongTensor([1,2,3,4])).shape"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:57.966034Z","iopub.status.busy":"2024-05-18T08:41:57.965656Z","iopub.status.idle":"2024-05-18T08:41:57.983335Z","shell.execute_reply":"2024-05-18T08:41:57.982272Z","shell.execute_reply.started":"2024-05-18T08:41:57.965999Z"},"id":"rP64KizDNQIa","trusted":true},"outputs":[],"source":["class PositionalEncoder(nn.Module):\n","    def __init__(self, d_model, max_seq_length=200, dropout=0.1):\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(dropout)\n","\n","        pe = torch.zeros(max_seq_length, d_model)\n","\n","        # Bảng pe mình vẽ ở trên\n","        for pos in range(max_seq_length):\n","            for i in range(0, d_model, 2):\n","                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n","                pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","\n","        x = x*math.sqrt(self.d_model)\n","        seq_length = x.size(1)\n","\n","        pe = Variable(self.pe[:, :seq_length], requires_grad=False)\n","\n","        if x.is_cuda:\n","            pe.cuda()\n","        # cộng embedding vector với pe\n","        x = x + pe\n","        x = self.dropout(x)\n","\n","        return x\n","\n","# PositionalEncoder(512)(torch.rand(5, 30, 512)).shape"]},{"cell_type":"markdown","metadata":{"id":"LdEQKhVvNiSz"},"source":["# Encoder\n","\n","## Self Attention Layer"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:57.984939Z","iopub.status.busy":"2024-05-18T08:41:57.984599Z","iopub.status.idle":"2024-05-18T08:41:57.997657Z","shell.execute_reply":"2024-05-18T08:41:57.996731Z","shell.execute_reply.started":"2024-05-18T08:41:57.984908Z"},"id":"2nJMcGuUNQId","trusted":true},"outputs":[],"source":["def attention(q, k, v, mask=None, dropout=None):\n","    \"\"\"\n","    q: batch_size x head x seq_length x d_model\n","    k: batch_size x head x seq_length x d_model\n","    v: batch_size x head x seq_length x d_model\n","    mask: batch_size x 1 x 1 x seq_length\n","    output: batch_size x head x seq_length x d_model\n","    \"\"\"\n","\n","    # attention score được tính bằng cách nhân q với k\n","    d_k = q.size(-1)\n","    scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(d_k)\n","\n","    if mask is not None:\n","        mask = mask.unsqueeze(1)\n","        scores = scores.masked_fill(mask==0, -1e9)\n","    # xong rồi thì chuẩn hóa bằng softmax\n","    scores = F.softmax(scores, dim=-1)\n","\n","    if dropout is not None:\n","        scores = dropout(scores)\n","\n","    output = torch.matmul(scores, v)\n","    return output, scores\n","\n","# attention(torch.rand(32, 8, 30, 512), torch.rand(32, 8, 30, 512), torch.rand(32, 8, 30, 512)).shape"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:57.999656Z","iopub.status.busy":"2024-05-18T08:41:57.998962Z","iopub.status.idle":"2024-05-18T08:41:58.011644Z","shell.execute_reply":"2024-05-18T08:41:58.010742Z","shell.execute_reply.started":"2024-05-18T08:41:57.999623Z"},"id":"ANQ4C3EENQIh","trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, heads, d_model, dropout=0.1):\n","        super().__init__()\n","        assert d_model % heads == 0\n","\n","        self.d_model = d_model\n","        self.d_k = d_model//heads\n","        self.h = heads\n","        self.attn = None\n","\n","        # tạo ra 3 ma trận trọng số là q_linear, k_linear, v_linear như hình trên\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.out = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        \"\"\"\n","        q: batch_size x seq_length x d_model\n","        k: batch_size x seq_length x d_model\n","        v: batch_size x seq_length x d_model\n","        mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","        bs = q.size(0)\n","        # nhân ma trận trọng số q_linear, k_linear, v_linear với dữ liệu đầu vào q, k, v\n","        # ở bước encode các bạn lưu ý rằng q, k, v chỉ là một (xem hình trên)\n","        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n","        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n","\n","        q = q.transpose(1, 2)\n","        k = k.transpose(1, 2)\n","        v = v.transpose(1, 2)\n","\n","        # tính attention score\n","        scores, self.attn = attention(q, k, v, mask, self.dropout)\n","\n","        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n","\n","        output = self.out(concat)\n","        return output\n","\n","# MultiHeadAttention(8, 512)(torch.rand(32, 30, 512), torch.rand(32, 30, 512), torch.rand(32, 30, 512)).shape"]},{"cell_type":"markdown","metadata":{"id":"uvOrq4-WPXYK"},"source":["# Residuals Connection và Normalization Layer"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.013124Z","iopub.status.busy":"2024-05-18T08:41:58.012784Z","iopub.status.idle":"2024-05-18T08:41:58.024595Z","shell.execute_reply":"2024-05-18T08:41:58.023729Z","shell.execute_reply.started":"2024-05-18T08:41:58.013090Z"},"id":"n6-_9Hq-NQIk","trusted":true},"outputs":[],"source":["class Norm(nn.Module):\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","\n","        self.size = d_model\n","\n","        # create two learnable parameters to calibrate normalisation\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n","        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","        return norm"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.026306Z","iopub.status.busy":"2024-05-18T08:41:58.025740Z","iopub.status.idle":"2024-05-18T08:41:58.037847Z","shell.execute_reply":"2024-05-18T08:41:58.036835Z","shell.execute_reply.started":"2024-05-18T08:41:58.026273Z"},"id":"H1ndbdMXNQIn","trusted":true},"outputs":[],"source":["class FeedForward(nn.Module):\n","    \"\"\" Trong kiến trúc của chúng ta có tầng linear\n","    \"\"\"\n","    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n","        super().__init__()\n","\n","        # We set d_ff as a default to 2048\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","\n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.041798Z","iopub.status.busy":"2024-05-18T08:41:58.041518Z","iopub.status.idle":"2024-05-18T08:41:58.050008Z","shell.execute_reply":"2024-05-18T08:41:58.049159Z","shell.execute_reply.started":"2024-05-18T08:41:58.041774Z"},"id":"-Wwo91xDNQIq","trusted":true},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.ff = FeedForward(d_model, dropout=dropout)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        \"\"\"\n","        x: batch_size x seq_length x d_model\n","        mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","\n","\n","        x2 = self.norm_1(x)\n","        # tính attention value, các bạn để ý q, k, v là giống nhau\n","        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n","        x2 = self.norm_2(x)\n","        x = x + self.dropout_2(self.ff(x2))\n","        return x\n","\n","# EncoderLayer(512, 8)(torch.rand(32, 30, 512), torch.rand(32 , 1, 30)).shape"]},{"cell_type":"markdown","metadata":{"id":"48SiXL_zQQ9C"},"source":["# Decoder\n","## Masked Multi Head Attention"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.051400Z","iopub.status.busy":"2024-05-18T08:41:58.051039Z","iopub.status.idle":"2024-05-18T08:41:58.060809Z","shell.execute_reply":"2024-05-18T08:41:58.059823Z","shell.execute_reply.started":"2024-05-18T08:41:58.051365Z"},"id":"6mDt2NPeNQIu","trusted":true},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        self.dropout_3 = nn.Dropout(dropout)\n","\n","        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.ff = FeedForward(d_model, dropout=dropout)\n","\n","    def forward(self, x, e_outputs, src_mask, trg_mask):\n","        \"\"\"\n","        x: batch_size x seq_length x d_model\n","        e_outputs: batch_size x seq_length x d_model\n","        src_mask: batch_size x 1 x seq_length\n","        trg_mask: batch_size x 1 x seq_length\n","        \"\"\"\n","        # Các bạn xem hình trên, kiến trúc mình vẽ với code ở chỗ này tương đương nhau.\n","        x2 = self.norm_1(x)\n","        # multihead attention thứ nhất, chú ý các từ ở target\n","        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n","        x2 = self.norm_2(x)\n","        # masked mulithead attention thứ 2. k, v là giá trị output của mô hình encoder\n","        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n","        x2 = self.norm_3(x)\n","        x = x + self.dropout_3(self.ff(x2))\n","        return x\n","\n","# DecoderLayer(512, 8)(torch.rand(32, 30, 512), torch.rand(32, 30, 512), torch.rand(32, 1, 30), torch.rand(32, 1, 30)).shape"]},{"cell_type":"markdown","metadata":{"id":"lk1c6NkYIeG8"},"source":["# Cài đặt Encoder"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.062144Z","iopub.status.busy":"2024-05-18T08:41:58.061840Z","iopub.status.idle":"2024-05-18T08:41:58.074564Z","shell.execute_reply":"2024-05-18T08:41:58.073739Z","shell.execute_reply.started":"2024-05-18T08:41:58.062119Z"},"id":"ZcU8nyvzNQIx","trusted":true},"outputs":[],"source":["import copy\n","\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n","\n","class Encoder(nn.Module):\n","    \"\"\"Một encoder có nhiều encoder layer nhé !!!\n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model, dropout=dropout)\n","        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","\n","    def forward(self, src, mask):\n","        \"\"\"\n","        src: batch_size x seq_length\n","        mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","        x = self.embed(src)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, mask)\n","        return self.norm(x)\n","\n","# Encoder(232, 512,6,8,0.1)(torch.LongTensor(32, 30).random_(0, 10), torch.rand(32, 1, 30)).shape"]},{"cell_type":"markdown","metadata":{"id":"Qip-E_TAIpmJ"},"source":["# Cài đặt Decoder"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.076032Z","iopub.status.busy":"2024-05-18T08:41:58.075717Z","iopub.status.idle":"2024-05-18T08:41:58.089091Z","shell.execute_reply":"2024-05-18T08:41:58.088133Z","shell.execute_reply.started":"2024-05-18T08:41:58.076008Z"},"id":"5lBRYMg_NQI0","trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    \"\"\"Một decoder có nhiều decoder layer nhé !!!\n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model, dropout=dropout)\n","        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e_outputs, src_mask, trg_mask):\n","        \"\"\"\n","        trg: batch_size x seq_length\n","        e_outputs: batch_size x seq_length x d_model\n","        src_mask: batch_size x 1 x seq_length\n","        trg_mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n","        return self.norm(x)\n","\n","# Decoder(232, 512, 6, 8, 0.1)(torch.LongTensor(32, 30).random_(0, 10), torch.rand(32, 30, 512), torch.rand(32, 1, 30), torch.rand(32, 1, 30)).shape"]},{"cell_type":"markdown","metadata":{"id":"gDVQGAaMI5UU"},"source":["# Cài đặt Transformer"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.090969Z","iopub.status.busy":"2024-05-18T08:41:58.090387Z","iopub.status.idle":"2024-05-18T08:41:58.100277Z","shell.execute_reply":"2024-05-18T08:41:58.099469Z","shell.execute_reply.started":"2024-05-18T08:41:58.090935Z"},"id":"DpxSCRILNQI3","trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    \"\"\" Cuối cùng ghép chúng lại với nhau để được mô hình transformer hoàn chỉnh\n","    \"\"\"\n","    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n","        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        \"\"\"\n","        src: batch_size x seq_length\n","        trg: batch_size x seq_length\n","        src_mask: batch_size x 1 x seq_length\n","        trg_mask batch_size x 1 x seq_length\n","        output: batch_size x seq_length x vocab_size\n","        \"\"\"\n","        e_outputs = self.encoder(src, src_mask)\n","\n","        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output\n","\n","# Transformer(232, 232, 512, 6, 8, 0.1)(torch.LongTensor(32, 30).random_(0, 10), torch.LongTensor(32, 30).random_(0, 10),torch.rand(32, 1, 30),torch.rand(32, 1, 30)).shape"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.101694Z","iopub.status.busy":"2024-05-18T08:41:58.101398Z","iopub.status.idle":"2024-05-18T08:41:58.191437Z","shell.execute_reply":"2024-05-18T08:41:58.190706Z","shell.execute_reply.started":"2024-05-18T08:41:58.101670Z"},"id":"M5tvzW9jNQI6","trusted":true},"outputs":[],"source":["from torchtext import data\n","\n","class MyIterator(data.Iterator):\n","    def create_batches(self):\n","        if self.train:\n","            def pool(d, random_shuffler):\n","                for p in data.batch(d, self.batch_size * 100):\n","                    p_batch = data.batch(\n","                        sorted(p, key=self.sort_key),\n","                        self.batch_size, self.batch_size_fn)\n","                    for b in random_shuffler(list(p_batch)):\n","                        yield b\n","            self.batches = pool(self.data(), self.random_shuffler)\n","\n","        else:\n","            self.batches = []\n","            for b in data.batch(self.data(), self.batch_size,\n","                                          self.batch_size_fn):\n","                self.batches.append(sorted(b, key=self.sort_key))\n","\n","global max_src_in_batch, max_tgt_in_batch\n","\n","def batch_size_fn(new, count, sofar):\n","    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n","    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n","    src_elements = count * max_src_in_batch\n","    tgt_elements = count * max_tgt_in_batch\n","    return max(src_elements, tgt_elements)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.192862Z","iopub.status.busy":"2024-05-18T08:41:58.192525Z","iopub.status.idle":"2024-05-18T08:41:58.201249Z","shell.execute_reply":"2024-05-18T08:41:58.200402Z","shell.execute_reply.started":"2024-05-18T08:41:58.192830Z"},"id":"NkBjLH96NQI8","trusted":true},"outputs":[],"source":["\n","def nopeak_mask(size, device):\n","    \"\"\"Tạo mask được sử dụng trong decoder để lúc dự đoán trong quá trình huấn luyện\n","     mô hình không nhìn thấy được các từ ở tương lai\n","    \"\"\"\n","    np_mask = np.triu(np.ones((1, size, size)),\n","    k=1).astype('uint8')\n","    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n","    np_mask = np_mask.to(device)\n","\n","    return np_mask\n","\n","def create_masks(src, trg, src_pad, trg_pad, device):\n","    \"\"\" Tạo mask cho encoder,\n","    để mô hình không bỏ qua thông tin của các kí tự PAD do chúng ta thêm vào\n","    \"\"\"\n","    src_mask = (src != src_pad).unsqueeze(-2)\n","\n","    if trg is not None:\n","        trg_mask = (trg != trg_pad).unsqueeze(-2)\n","        size = trg.size(1) # get seq_len for matrix\n","        np_mask = nopeak_mask(size, device)\n","        if trg.is_cuda:\n","            np_mask.cuda()\n","        trg_mask = trg_mask & np_mask\n","\n","    else:\n","        trg_mask = None\n","    return src_mask, trg_mask"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.202652Z","iopub.status.busy":"2024-05-18T08:41:58.202382Z","iopub.status.idle":"2024-05-18T08:41:58.213945Z","shell.execute_reply":"2024-05-18T08:41:58.213039Z","shell.execute_reply.started":"2024-05-18T08:41:58.202628Z"},"id":"9YoUVx4xjEb7","trusted":true},"outputs":[],"source":["from nltk.corpus import wordnet\n","import re\n","\n","def get_synonym(word, SRC):\n","    syns = wordnet.synsets(word)\n","    for s in syns:\n","        for l in s.lemmas():\n","            if SRC.vocab.stoi[l.name()] != 0:\n","                return SRC.vocab.stoi[l.name()]\n","\n","    return 0\n","\n","def multiple_replace(dict, text):\n","  # Create a regular expression  from the dictionary keys\n","  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n","\n","  # For each match, look-up corresponding value in dictionary\n","  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.215350Z","iopub.status.busy":"2024-05-18T08:41:58.215061Z","iopub.status.idle":"2024-05-18T08:41:58.236423Z","shell.execute_reply":"2024-05-18T08:41:58.235561Z","shell.execute_reply.started":"2024-05-18T08:41:58.215326Z"},"id":"1IJpUEIMgMbw","trusted":true},"outputs":[],"source":["def init_vars(src, model, SRC, TRG, device, k, max_len):\n","    \"\"\" Tính toán các ma trận cần thiết trong quá trình translation sau khi mô hình học xong\n","    \"\"\"\n","    init_tok = TRG.vocab.stoi['<sos>']\n","    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n","\n","    # tính sẵn output của encoder\n","    e_output = model.encoder(src, src_mask)\n","\n","    outputs = torch.LongTensor([[init_tok]])\n","\n","    outputs = outputs.to(device)\n","\n","    trg_mask = nopeak_mask(1, device)\n","    # dự đoán kí tự đầu tiên\n","    out = model.out(model.decoder(outputs,\n","    e_output, src_mask, trg_mask))\n","    out = F.softmax(out, dim=-1)\n","\n","    probs, ix = out[:, -1].data.topk(k)\n","    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n","\n","    outputs = torch.zeros(k, max_len).long()\n","    outputs = outputs.to(device)\n","    outputs[:, 0] = init_tok\n","    outputs[:, 1] = ix[0]\n","\n","    e_outputs = torch.zeros(k, e_output.size(-2),e_output.size(-1))\n","\n","    e_outputs = e_outputs.to(device)\n","    e_outputs[:, :] = e_output[0]\n","\n","    return outputs, e_outputs, log_scores\n","\n","def k_best_outputs(outputs, out, log_scores, i, k):\n","\n","    probs, ix = out[:, -1].data.topk(k)\n","    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n","    k_probs, k_ix = log_probs.view(-1).topk(k)\n","\n","    row = k_ix // k\n","    col = k_ix % k\n","\n","    outputs[:, :i] = outputs[row, :i]\n","    outputs[:, i] = ix[row, col]\n","\n","    log_scores = k_probs.unsqueeze(0)\n","\n","    return outputs, log_scores\n","\n","def beam_search(src, model, SRC, TRG, device, k, max_len):\n","\n","    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, device, k, max_len)\n","    eos_tok = TRG.vocab.stoi['<eos>']\n","    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n","    ind = None\n","    for i in range(2, max_len):\n","\n","        trg_mask = nopeak_mask(i, device)\n","\n","        out = model.out(model.decoder(outputs[:,:i],\n","        e_outputs, src_mask, trg_mask))\n","\n","        out = F.softmax(out, dim=-1)\n","\n","        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, k)\n","\n","        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n","        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n","        for vec in ones:\n","            i = vec[0]\n","            if sentence_lengths[i]==0: # First end symbol has not been found yet\n","                sentence_lengths[i] = vec[1] # Position of first end symbol\n","\n","        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n","\n","        if num_finished_sentences == k:\n","            alpha = 0.7\n","            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n","            _, ind = torch.max(log_scores * div, 1)\n","            ind = ind.data[0]\n","            break\n","\n","    if ind is None:\n","\n","        length = (outputs[0]==eos_tok).nonzero()[0] if len((outputs[0]==eos_tok).nonzero()) > 0 else -1\n","        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n","\n","    else:\n","        length = (outputs[ind]==eos_tok).nonzero()[0]\n","        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.237864Z","iopub.status.busy":"2024-05-18T08:41:58.237528Z","iopub.status.idle":"2024-05-18T08:41:58.249271Z","shell.execute_reply":"2024-05-18T08:41:58.248524Z","shell.execute_reply.started":"2024-05-18T08:41:58.237832Z"},"id":"s-AFuSOIhi7X","trusted":true},"outputs":[],"source":["def translate_sentence(sentence, model, SRC, TRG, device, k, max_len):\n","    \"\"\"Dịch một câu sử dụng beamsearch\n","    \"\"\"\n","    model.eval()\n","    indexed = []\n","    sentence = SRC.preprocess(sentence)\n","\n","    for tok in sentence:\n","        if SRC.vocab.stoi[tok] != SRC.vocab.stoi['<eos>']:\n","            indexed.append(SRC.vocab.stoi[tok])\n","        else:\n","            indexed.append(get_synonym(tok, SRC))\n","\n","    sentence = Variable(torch.LongTensor([indexed]))\n","\n","    sentence = sentence.to(device)\n","\n","    sentence = beam_search(sentence, model, SRC, TRG, device, k, max_len)\n","\n","    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:41:58.250715Z","iopub.status.busy":"2024-05-18T08:41:58.250449Z","iopub.status.idle":"2024-05-18T08:42:03.281819Z","shell.execute_reply":"2024-05-18T08:42:03.281053Z","shell.execute_reply.started":"2024-05-18T08:41:58.250691Z"},"id":"4Uee4YaQNQI_","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-18 08:41:59.660063: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-18 08:41:59.660123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-18 08:41:59.661526: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import spacy\n","import re\n","\n","class tokenize(object):\n","\n","    def __init__(self, lang):\n","        self.nlp = spacy.load(lang)\n","\n","    def tokenizer(self, sentence):\n","        sentence = re.sub(\n","        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n","        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n","        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n","        sentence = re.sub(r\"\\,+\", \",\", sentence)\n","        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n","        sentence = sentence.lower()\n","        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"]},{"cell_type":"markdown","metadata":{"id":"x2jMF9lzQ4a8"},"source":["## Data loader"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.284003Z","iopub.status.busy":"2024-05-18T08:42:03.283057Z","iopub.status.idle":"2024-05-18T08:42:03.297461Z","shell.execute_reply":"2024-05-18T08:42:03.296282Z","shell.execute_reply.started":"2024-05-18T08:42:03.283967Z"},"id":"_uVO0yr_NQJC","trusted":true},"outputs":[],"source":["import os\n","import dill as pickle\n","import pandas as pd\n","\n","def read_data(src_file, trg_file):\n","    src_data = open(src_file).read().strip().split('\\n')\n","\n","    trg_data = open(trg_file).read().strip().split('\\n')\n","\n","    return src_data, trg_data\n","\n","def create_fields(src_lang, trg_lang):\n","\n","    print(\"loading spacy tokenizers...\")\n","\n","    t_src = tokenize(src_lang)\n","    t_trg = tokenize(trg_lang)\n","\n","    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n","    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n","\n","    return SRC, TRG\n","\n","def create_dataset(src_data, trg_data, max_strlen, batchsize, device, SRC, TRG, istrain=True):\n","\n","    print(\"creating dataset and iterator... \")\n","\n","    raw_data = {'src' : [line for line in src_data], 'trg': [line for line in trg_data]}\n","    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n","\n","    mask = (df['src'].str.count(' ') < max_strlen) & (df['trg'].str.count(' ') < max_strlen)\n","    df = df.loc[mask]\n","\n","    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n","\n","    data_fields = [('src', SRC), ('trg', TRG)]\n","    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n","\n","    train_iter = MyIterator(train, batch_size=batchsize, device=device,\n","                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n","                        batch_size_fn=batch_size_fn, train=istrain, shuffle=True)\n","\n","    os.remove('translate_transformer_temp.csv')\n","\n","    if istrain:\n","        SRC.build_vocab(train)\n","        TRG.build_vocab(train)\n","\n","    return train_iter\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.299675Z","iopub.status.busy":"2024-05-18T08:42:03.299147Z","iopub.status.idle":"2024-05-18T08:42:03.320048Z","shell.execute_reply":"2024-05-18T08:42:03.319187Z","shell.execute_reply.started":"2024-05-18T08:42:03.299642Z"},"id":"l4POJRxdNQJF","trusted":true},"outputs":[],"source":["def step(model, optimizer,batch, criterion):\n","    \"\"\"\n","    Một lần cập nhật mô hình\n","    \"\"\"\n","    model.train()\n","\n","    src = batch.src.transpose(0,1).cuda()\n","    trg = batch.trg.transpose(0,1).cuda()\n","    trg_input = trg[:, :-1]\n","    src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n","    preds = model(src, trg_input, src_mask, trg_mask)\n","\n","    ys = trg[:, 1:].contiguous().view(-1)\n","\n","    optimizer.zero_grad()\n","    loss = criterion(preds.view(-1, preds.size(-1)), ys)\n","    loss.backward()\n","    optimizer.step_and_update_lr()\n","\n","    loss = loss.item()\n","\n","    return loss"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.321369Z","iopub.status.busy":"2024-05-18T08:42:03.321074Z","iopub.status.idle":"2024-05-18T08:42:03.334773Z","shell.execute_reply":"2024-05-18T08:42:03.334033Z","shell.execute_reply.started":"2024-05-18T08:42:03.321345Z"},"id":"c5sPA-k_NQJI","trusted":true},"outputs":[],"source":["def validiate(model, valid_iter, criterion):\n","    \"\"\" Tính loss trên tập validation\n","    \"\"\"\n","    model.eval()\n","\n","    with torch.no_grad():\n","        total_loss = []\n","        for batch in valid_iter:\n","            src = batch.src.transpose(0,1).cuda()\n","            trg = batch.trg.transpose(0,1).cuda()\n","            trg_input = trg[:, :-1]\n","            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n","            preds = model(src, trg_input, src_mask, trg_mask)\n","\n","            ys = trg[:, 1:].contiguous().view(-1)\n","\n","            loss = criterion(preds.view(-1, preds.size(-1)), ys)\n","\n","            loss = loss.item()\n","\n","            total_loss.append(loss)\n","\n","    avg_loss = np.mean(total_loss)\n","\n","    return avg_loss"]},{"cell_type":"markdown","metadata":{"id":"QX4b6LLN47qC"},"source":["# Optimizer\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.336139Z","iopub.status.busy":"2024-05-18T08:42:03.335876Z","iopub.status.idle":"2024-05-18T08:42:03.346856Z","shell.execute_reply":"2024-05-18T08:42:03.346010Z","shell.execute_reply.started":"2024-05-18T08:42:03.336115Z"},"id":"OW8pRq91rwJR","trusted":true},"outputs":[],"source":["class ScheduledOptim():\n","    '''A simple wrapper class for learning rate scheduling'''\n","\n","    def __init__(self, optimizer, init_lr, d_model, n_warmup_steps):\n","        self._optimizer = optimizer\n","        self.init_lr = init_lr\n","        self.d_model = d_model\n","        self.n_warmup_steps = n_warmup_steps\n","        self.n_steps = 0\n","\n","\n","    def step_and_update_lr(self):\n","        \"Step with the inner optimizer\"\n","        self._update_learning_rate()\n","        self._optimizer.step()\n","\n","\n","    def zero_grad(self):\n","        \"Zero out the gradients with the inner optimizer\"\n","        self._optimizer.zero_grad()\n","\n","\n","    def _get_lr_scale(self):\n","        d_model = self.d_model\n","        n_steps, n_warmup_steps = self.n_steps, self.n_warmup_steps\n","        return (d_model ** -0.5) * min(n_steps ** (-0.5), n_steps * n_warmup_steps ** (-1.5))\n","\n","    def state_dict(self):\n","        optimizer_state_dict = {\n","            'init_lr':self.init_lr,\n","            'd_model':self.d_model,\n","            'n_warmup_steps':self.n_warmup_steps,\n","            'n_steps':self.n_steps,\n","            '_optimizer':self._optimizer.state_dict(),\n","        }\n","\n","        return optimizer_state_dict\n","\n","    def load_state_dict(self, state_dict):\n","        self.init_lr = state_dict['init_lr']\n","        self.d_model = state_dict['d_model']\n","        self.n_warmup_steps = state_dict['n_warmup_steps']\n","        self.n_steps = state_dict['n_steps']\n","\n","        self._optimizer.load_state_dict(state_dict['_optimizer'])\n","\n","    def _update_learning_rate(self):\n","        ''' Learning rate scheduling per step '''\n","\n","        self.n_steps += 1\n","        lr = self.init_lr * self._get_lr_scale()\n","\n","        for param_group in self._optimizer.param_groups:\n","            param_group['lr'] = lr"]},{"cell_type":"markdown","metadata":{"id":"TKJoYats5LYn"},"source":["# Label Smoothing\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.348651Z","iopub.status.busy":"2024-05-18T08:42:03.347951Z","iopub.status.idle":"2024-05-18T08:42:03.359915Z","shell.execute_reply":"2024-05-18T08:42:03.359019Z","shell.execute_reply.started":"2024-05-18T08:42:03.348624Z"},"id":"LHGeSHThtlj-","trusted":true},"outputs":[],"source":["class LabelSmoothingLoss(nn.Module):\n","    def __init__(self, classes, padding_idx, smoothing=0.0, dim=-1):\n","        super(LabelSmoothingLoss, self).__init__()\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.cls = classes\n","        self.dim = dim\n","        self.padding_idx = padding_idx\n","\n","    def forward(self, pred, target):\n","        pred = pred.log_softmax(dim=self.dim)\n","        with torch.no_grad():\n","            # true_dist = pred.data.clone()\n","            true_dist = torch.zeros_like(pred)\n","            true_dist.fill_(self.smoothing / (self.cls - 2))\n","            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","            true_dist[:, self.padding_idx] = 0\n","            mask = torch.nonzero(target.data == self.padding_idx, as_tuple=False)\n","            if mask.dim() > 0:\n","                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","\n","        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.373724Z","iopub.status.busy":"2024-05-18T08:42:03.373412Z","iopub.status.idle":"2024-05-18T08:42:03.459348Z","shell.execute_reply":"2024-05-18T08:42:03.458148Z","shell.execute_reply.started":"2024-05-18T08:42:03.373692Z"},"trusted":true},"outputs":[],"source":["import sacrebleu\n","\n","def bleu(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n","    \"\"\"Calculates SacreBLEU score using the Hugging Face evaluate library.\"\"\"\n","    pred_sents = []\n","    for sentence in valid_src_data:\n","        pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n","        pred_sents.append(pred_trg)\n","\n","    trg_sents = [[sent] for sent in valid_trg_data]\n","\n","    bleu = sacrebleu.corpus_bleu(pred_sents, trg_sents)\n","    return bleu.score"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:42:03.465838Z","iopub.status.busy":"2024-05-18T08:42:03.465186Z","iopub.status.idle":"2024-05-18T08:42:03.473657Z","shell.execute_reply":"2024-05-18T08:42:03.472444Z","shell.execute_reply.started":"2024-05-18T08:42:03.465811Z"},"id":"Nhgu-SPTNQJL","trusted":true},"outputs":[],"source":["opt = {\n","    'train_src_data':'/kaggle/input/phomt-vietnamese-english-machine-translation/PhoMT/tokenization/train/train.en',\n","    'train_trg_data':'/kaggle/input/phomt-vietnamese-english-machine-translation/PhoMT/tokenization/train/train.vi',\n","    'valid_src_data':'/kaggle/input/phomt-vietnamese-english-machine-translation/PhoMT/tokenization/dev/dev.en',\n","    'valid_trg_data':'/kaggle/input/phomt-vietnamese-english-machine-translation/PhoMT/tokenization/dev/dev.vi',\n","    'src_lang':'en_core_web_sm',\n","    'trg_lang':'vi_core_news_lg',#'vi_spacy_model',\n","    'max_strlen':160,\n","    'batchsize':1500,\n","    'device':'cuda',\n","    'd_model': 512,\n","    'n_layers': 6,\n","    'heads': 8,\n","    'dropout': 0.1,\n","    'lr':0.0001,\n","    'epochs':30,\n","    'printevery': 200,\n","    'k':5,\n","}"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-18T08:42:03.475641Z","iopub.status.busy":"2024-05-18T08:42:03.475292Z","iopub.status.idle":"2024-05-18T08:44:06.635775Z","shell.execute_reply":"2024-05-18T08:44:06.634976Z","shell.execute_reply.started":"2024-05-18T08:42:03.475604Z"},"id":"IBotIB8pNQJU","outputId":"6aa69246-3ad8-4525-ed36-2e3a7eeeef6f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["loading spacy tokenizers...\n","creating dataset and iterator... \n","creating dataset and iterator... \n"]}],"source":["train_src_data, train_trg_data = read_data(opt['train_src_data'], opt['train_trg_data'])\n","valid_src_data, valid_trg_data = read_data(opt['valid_src_data'], opt['valid_trg_data'])\n","\n","train_src_data = train_src_data[200000:330000]\n","train_trg_data = train_trg_data[200000:330000]\n","valid_src_data = valid_src_data[:1200]\n","valid_trg_data = valid_trg_data[:1200]\n","\n","SRC, TRG = create_fields(opt['src_lang'], opt['trg_lang'])\n","train_iter = create_dataset(train_src_data, train_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\n","valid_iter = create_dataset(valid_src_data, valid_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:44:06.637352Z","iopub.status.busy":"2024-05-18T08:44:06.637019Z","iopub.status.idle":"2024-05-18T08:44:06.641998Z","shell.execute_reply":"2024-05-18T08:44:06.641038Z","shell.execute_reply.started":"2024-05-18T08:44:06.637325Z"},"id":"Gnw9xrJeNQJX","trusted":true},"outputs":[],"source":["src_pad = SRC.vocab.stoi['<pad>']\n","trg_pad = TRG.vocab.stoi['<pad>']"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"execution":{"iopub.execute_input":"2024-05-18T08:44:06.643856Z","iopub.status.busy":"2024-05-18T08:44:06.643290Z","iopub.status.idle":"2024-05-18T08:44:09.989137Z","shell.execute_reply":"2024-05-18T08:44:09.988136Z","shell.execute_reply.started":"2024-05-18T08:44:06.643821Z"},"id":"5RccNL8VNQJd","outputId":"ab5c6941-476c-4663-d87e-09607a3145e1","trusted":true},"outputs":[],"source":["model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","model = model.to(opt['device'])"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:44:09.991819Z","iopub.status.busy":"2024-05-18T08:44:09.990958Z","iopub.status.idle":"2024-05-18T08:44:10.800860Z","shell.execute_reply":"2024-05-18T08:44:10.799906Z","shell.execute_reply.started":"2024-05-18T08:44:09.991782Z"},"id":"12debLGiNQJg","trusted":true},"outputs":[],"source":["optimizer = ScheduledOptim(\n","        torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n","        0.2, opt['d_model'], 4000)\n","\n","criterion = LabelSmoothingLoss(len(TRG.vocab), padding_idx=trg_pad, smoothing=0.1)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T08:44:10.802821Z","iopub.status.busy":"2024-05-18T08:44:10.802178Z","iopub.status.idle":"2024-05-18T12:12:24.440762Z","shell.execute_reply":"2024-05-18T12:12:24.439652Z","shell.execute_reply.started":"2024-05-18T08:44:10.802787Z"},"id":"JeZqfQPANQJl","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 000 - iter: 00199 - train loss: 9.8747 - time: 0.1333\n","epoch: 000 - iter: 00399 - train loss: 9.0873 - time: 0.1298\n","epoch: 000 - iter: 00599 - train loss: 7.8099 - time: 0.1302\n","epoch: 000 - iter: 00799 - train loss: 6.9537 - time: 0.1291\n","epoch: 000 - iter: 00999 - train loss: 6.7273 - time: 0.1256\n","epoch: 000 - iter: 01199 - train loss: 6.6210 - time: 0.1259\n","epoch: 000 - iter: 01399 - train loss: 6.5160 - time: 0.1288\n","epoch: 000 - iter: 01599 - train loss: 6.3616 - time: 0.1271\n","epoch: 000 - iter: 01799 - train loss: 6.2800 - time: 0.1306\n","epoch: 000 - iter: 01988 - valid loss: 4.8780 - bleu score: 12.0749 - time: 164.1446\n","epoch: 001 - iter: 00199 - train loss: 6.0803 - time: 0.1176\n","epoch: 001 - iter: 00399 - train loss: 5.9607 - time: 0.1195\n","epoch: 001 - iter: 00599 - train loss: 5.8719 - time: 0.1228\n","epoch: 001 - iter: 00799 - train loss: 5.7136 - time: 0.1294\n","epoch: 001 - iter: 00999 - train loss: 5.6021 - time: 0.1313\n","epoch: 001 - iter: 01199 - train loss: 5.5573 - time: 0.1331\n","epoch: 001 - iter: 01399 - train loss: 5.4746 - time: 0.1310\n","epoch: 001 - iter: 01599 - train loss: 5.3520 - time: 0.1321\n","epoch: 001 - iter: 01799 - train loss: 5.3053 - time: 0.1335\n","epoch: 001 - iter: 01988 - valid loss: 4.1569 - bleu score: 24.1635 - time: 109.6518\n","epoch: 002 - iter: 00199 - train loss: 5.1138 - time: 0.1245\n","epoch: 002 - iter: 00399 - train loss: 4.9715 - time: 0.1346\n","epoch: 002 - iter: 00599 - train loss: 4.8874 - time: 0.1348\n","epoch: 002 - iter: 00799 - train loss: 4.8395 - time: 0.1246\n","epoch: 002 - iter: 00999 - train loss: 4.7468 - time: 0.1224\n","epoch: 002 - iter: 01199 - train loss: 4.6903 - time: 0.1323\n","epoch: 002 - iter: 01399 - train loss: 4.6551 - time: 0.1296\n","epoch: 002 - iter: 01599 - train loss: 4.6188 - time: 0.1339\n","epoch: 002 - iter: 01799 - train loss: 4.6555 - time: 0.1335\n","epoch: 002 - iter: 01988 - valid loss: 3.6511 - bleu score: 35.3599 - time: 141.4106\n","epoch: 003 - iter: 00199 - train loss: 4.3609 - time: 0.1286\n","epoch: 003 - iter: 00399 - train loss: 4.3448 - time: 0.1263\n","epoch: 003 - iter: 00599 - train loss: 4.3214 - time: 0.1282\n","epoch: 003 - iter: 00799 - train loss: 4.2750 - time: 0.1252\n","epoch: 003 - iter: 00999 - train loss: 4.2315 - time: 0.1258\n","epoch: 003 - iter: 01199 - train loss: 4.2572 - time: 0.1231\n","epoch: 003 - iter: 01399 - train loss: 4.1890 - time: 0.1339\n","epoch: 003 - iter: 01599 - train loss: 4.2183 - time: 0.1335\n","epoch: 003 - iter: 01799 - train loss: 4.1636 - time: 0.1232\n","epoch: 003 - iter: 01988 - valid loss: 3.4206 - bleu score: 32.4891 - time: 151.6034\n","epoch: 004 - iter: 00199 - train loss: 3.9848 - time: 0.1311\n","epoch: 004 - iter: 00399 - train loss: 3.9814 - time: 0.1262\n","epoch: 004 - iter: 00599 - train loss: 3.9389 - time: 0.1343\n","epoch: 004 - iter: 00799 - train loss: 3.9768 - time: 0.1258\n","epoch: 004 - iter: 00999 - train loss: 3.9939 - time: 0.1286\n","epoch: 004 - iter: 01199 - train loss: 3.9354 - time: 0.1285\n","epoch: 004 - iter: 01399 - train loss: 3.9219 - time: 0.1288\n","epoch: 004 - iter: 01599 - train loss: 3.9193 - time: 0.1311\n","epoch: 004 - iter: 01799 - train loss: 3.9076 - time: 0.1312\n","epoch: 004 - iter: 01988 - valid loss: 3.2854 - bleu score: 26.9696 - time: 161.7539\n","epoch: 005 - iter: 00199 - train loss: 3.7673 - time: 0.1295\n","epoch: 005 - iter: 00399 - train loss: 3.7866 - time: 0.1306\n","epoch: 005 - iter: 00599 - train loss: 3.7647 - time: 0.1257\n","epoch: 005 - iter: 00799 - train loss: 3.7731 - time: 0.1319\n","epoch: 005 - iter: 00999 - train loss: 3.7790 - time: 0.1260\n","epoch: 005 - iter: 01199 - train loss: 3.7427 - time: 0.1349\n","epoch: 005 - iter: 01399 - train loss: 3.7372 - time: 0.1266\n","epoch: 005 - iter: 01599 - train loss: 3.7384 - time: 0.1240\n","epoch: 005 - iter: 01799 - train loss: 3.7330 - time: 0.1318\n","epoch: 005 - iter: 01988 - valid loss: 3.2124 - bleu score: 25.8569 - time: 147.4369\n","epoch: 006 - iter: 00199 - train loss: 3.6342 - time: 0.1260\n","epoch: 006 - iter: 00399 - train loss: 3.5767 - time: 0.1337\n","epoch: 006 - iter: 00599 - train loss: 3.5873 - time: 0.1273\n","epoch: 006 - iter: 00799 - train loss: 3.6142 - time: 0.1248\n","epoch: 006 - iter: 00999 - train loss: 3.6251 - time: 0.1251\n","epoch: 006 - iter: 01199 - train loss: 3.6347 - time: 0.1304\n","epoch: 006 - iter: 01399 - train loss: 3.6569 - time: 0.1318\n","epoch: 006 - iter: 01599 - train loss: 3.6115 - time: 0.1321\n","epoch: 006 - iter: 01799 - train loss: 3.6101 - time: 0.1287\n","epoch: 006 - iter: 01988 - valid loss: 3.1498 - bleu score: 24.6194 - time: 160.6630\n","epoch: 007 - iter: 00199 - train loss: 3.4592 - time: 0.1279\n","epoch: 007 - iter: 00399 - train loss: 3.4617 - time: 0.1263\n","epoch: 007 - iter: 00599 - train loss: 3.5236 - time: 0.1157\n","epoch: 007 - iter: 00799 - train loss: 3.4886 - time: 0.1256\n","epoch: 007 - iter: 00999 - train loss: 3.5316 - time: 0.1263\n","epoch: 007 - iter: 01199 - train loss: 3.5191 - time: 0.1333\n","epoch: 007 - iter: 01399 - train loss: 3.5489 - time: 0.1268\n","epoch: 007 - iter: 01599 - train loss: 3.4882 - time: 0.1312\n","epoch: 007 - iter: 01799 - train loss: 3.5062 - time: 0.1274\n","epoch: 007 - iter: 01988 - valid loss: 3.1186 - bleu score: 32.6407 - time: 146.7634\n","epoch: 008 - iter: 00199 - train loss: 3.3811 - time: 0.1338\n","epoch: 008 - iter: 00399 - train loss: 3.3987 - time: 0.1330\n","epoch: 008 - iter: 00599 - train loss: 3.4213 - time: 0.1204\n","epoch: 008 - iter: 00799 - train loss: 3.4289 - time: 0.1327\n","epoch: 008 - iter: 00999 - train loss: 3.3717 - time: 0.1325\n","epoch: 008 - iter: 01199 - train loss: 3.4341 - time: 0.1247\n","epoch: 008 - iter: 01399 - train loss: 3.4252 - time: 0.1295\n","epoch: 008 - iter: 01599 - train loss: 3.4143 - time: 0.1227\n","epoch: 008 - iter: 01799 - train loss: 3.4649 - time: 0.1261\n","epoch: 008 - iter: 01988 - valid loss: 3.0942 - bleu score: 24.0658 - time: 159.4900\n","epoch: 009 - iter: 00199 - train loss: 3.2893 - time: 0.1288\n","epoch: 009 - iter: 00399 - train loss: 3.3328 - time: 0.1321\n","epoch: 009 - iter: 00599 - train loss: 3.3314 - time: 0.1256\n","epoch: 009 - iter: 00799 - train loss: 3.3098 - time: 0.1256\n","epoch: 009 - iter: 00999 - train loss: 3.3394 - time: 0.1334\n","epoch: 009 - iter: 01199 - train loss: 3.3496 - time: 0.1278\n","epoch: 009 - iter: 01399 - train loss: 3.3428 - time: 0.1275\n","epoch: 009 - iter: 01599 - train loss: 3.3630 - time: 0.1245\n","epoch: 009 - iter: 01799 - train loss: 3.3904 - time: 0.1284\n","epoch: 009 - iter: 01988 - valid loss: 3.0784 - bleu score: 27.2406 - time: 155.3379\n","epoch: 010 - iter: 00199 - train loss: 3.2319 - time: 0.1265\n","epoch: 010 - iter: 00399 - train loss: 3.2742 - time: 0.1278\n","epoch: 010 - iter: 00599 - train loss: 3.2567 - time: 0.1313\n","epoch: 010 - iter: 00799 - train loss: 3.2516 - time: 0.1319\n","epoch: 010 - iter: 00999 - train loss: 3.3001 - time: 0.1232\n","epoch: 010 - iter: 01199 - train loss: 3.2905 - time: 0.1281\n","epoch: 010 - iter: 01399 - train loss: 3.2994 - time: 0.1249\n","epoch: 010 - iter: 01599 - train loss: 3.2851 - time: 0.1345\n","epoch: 010 - iter: 01799 - train loss: 3.2713 - time: 0.1272\n","epoch: 010 - iter: 01988 - valid loss: 3.0793 - bleu score: 26.8078 - time: 166.2735\n","epoch: 011 - iter: 00199 - train loss: 3.1827 - time: 0.1318\n","epoch: 011 - iter: 00399 - train loss: 3.1867 - time: 0.1316\n","epoch: 011 - iter: 00599 - train loss: 3.2039 - time: 0.1209\n","epoch: 011 - iter: 00799 - train loss: 3.2342 - time: 0.1298\n","epoch: 011 - iter: 00999 - train loss: 3.1921 - time: 0.1322\n","epoch: 011 - iter: 01199 - train loss: 3.2383 - time: 0.1313\n","epoch: 011 - iter: 01399 - train loss: 3.2377 - time: 0.1277\n","epoch: 011 - iter: 01599 - train loss: 3.2462 - time: 0.1197\n","epoch: 011 - iter: 01799 - train loss: 3.2436 - time: 0.1251\n","epoch: 011 - iter: 01988 - valid loss: 3.0825 - bleu score: 27.8822 - time: 147.1167\n","epoch: 012 - iter: 00199 - train loss: 3.1495 - time: 0.1249\n","epoch: 012 - iter: 00399 - train loss: 3.1178 - time: 0.1329\n","epoch: 012 - iter: 00599 - train loss: 3.1671 - time: 0.1348\n","epoch: 012 - iter: 00799 - train loss: 3.1771 - time: 0.1331\n","epoch: 012 - iter: 00999 - train loss: 3.1542 - time: 0.1301\n","epoch: 012 - iter: 01199 - train loss: 3.1953 - time: 0.1318\n","epoch: 012 - iter: 01399 - train loss: 3.1530 - time: 0.1211\n","epoch: 012 - iter: 01599 - train loss: 3.1933 - time: 0.1298\n","epoch: 012 - iter: 01799 - train loss: 3.1806 - time: 0.1159\n","epoch: 012 - iter: 01988 - valid loss: 3.0872 - bleu score: 26.3040 - time: 156.0883\n","epoch: 013 - iter: 00199 - train loss: 3.0603 - time: 0.1280\n","epoch: 013 - iter: 00399 - train loss: 3.1011 - time: 0.1296\n","epoch: 013 - iter: 00599 - train loss: 3.1158 - time: 0.1239\n","epoch: 013 - iter: 00799 - train loss: 3.1077 - time: 0.1139\n","epoch: 013 - iter: 00999 - train loss: 3.1262 - time: 0.1181\n","epoch: 013 - iter: 01199 - train loss: 3.1329 - time: 0.1314\n","epoch: 013 - iter: 01399 - train loss: 3.1231 - time: 0.1316\n","epoch: 013 - iter: 01599 - train loss: 3.1311 - time: 0.1252\n","epoch: 013 - iter: 01799 - train loss: 3.1447 - time: 0.1197\n","epoch: 013 - iter: 01988 - valid loss: 3.0760 - bleu score: 29.7284 - time: 155.2134\n","epoch: 014 - iter: 00199 - train loss: 3.0344 - time: 0.1272\n","epoch: 014 - iter: 00399 - train loss: 3.0439 - time: 0.1236\n","epoch: 014 - iter: 00599 - train loss: 3.0599 - time: 0.1260\n","epoch: 014 - iter: 00799 - train loss: 3.0941 - time: 0.1349\n","epoch: 014 - iter: 00999 - train loss: 3.0201 - time: 0.1360\n","epoch: 014 - iter: 01199 - train loss: 3.1001 - time: 0.1337\n","epoch: 014 - iter: 01399 - train loss: 3.0847 - time: 0.1356\n","epoch: 014 - iter: 01599 - train loss: 3.0978 - time: 0.1211\n","epoch: 014 - iter: 01799 - train loss: 3.1091 - time: 0.1236\n","epoch: 014 - iter: 01988 - valid loss: 3.0862 - bleu score: 20.5053 - time: 154.2901\n","epoch: 015 - iter: 00199 - train loss: 2.9976 - time: 0.1260\n","epoch: 015 - iter: 00399 - train loss: 3.0258 - time: 0.1276\n","epoch: 015 - iter: 00599 - train loss: 3.0189 - time: 0.1317\n","epoch: 015 - iter: 00799 - train loss: 3.0393 - time: 0.1317\n","epoch: 015 - iter: 00999 - train loss: 3.0389 - time: 0.1249\n","epoch: 015 - iter: 01199 - train loss: 3.0484 - time: 0.1198\n","epoch: 015 - iter: 01399 - train loss: 3.0337 - time: 0.1311\n","epoch: 015 - iter: 01599 - train loss: 3.0447 - time: 0.1318\n","epoch: 015 - iter: 01799 - train loss: 3.0220 - time: 0.1294\n","epoch: 015 - iter: 01988 - valid loss: 3.0800 - bleu score: 37.4213 - time: 156.1065\n","epoch: 016 - iter: 00199 - train loss: 2.9554 - time: 0.1308\n","epoch: 016 - iter: 00399 - train loss: 2.9718 - time: 0.1249\n","epoch: 016 - iter: 00599 - train loss: 3.0002 - time: 0.1294\n","epoch: 016 - iter: 00799 - train loss: 2.9929 - time: 0.1306\n","epoch: 016 - iter: 00999 - train loss: 2.9777 - time: 0.1258\n","epoch: 016 - iter: 01199 - train loss: 3.0135 - time: 0.1213\n","epoch: 016 - iter: 01399 - train loss: 3.0045 - time: 0.1211\n","epoch: 016 - iter: 01599 - train loss: 2.9857 - time: 0.1263\n","epoch: 016 - iter: 01799 - train loss: 3.0384 - time: 0.1328\n","epoch: 016 - iter: 01988 - valid loss: 3.0921 - bleu score: 26.2509 - time: 157.6241\n","epoch: 017 - iter: 00199 - train loss: 2.9499 - time: 0.1293\n","epoch: 017 - iter: 00399 - train loss: 2.9319 - time: 0.1264\n","epoch: 017 - iter: 00599 - train loss: 2.9569 - time: 0.1251\n","epoch: 017 - iter: 00799 - train loss: 2.9484 - time: 0.1318\n","epoch: 017 - iter: 00999 - train loss: 2.9590 - time: 0.1273\n","epoch: 017 - iter: 01199 - train loss: 2.9660 - time: 0.1293\n","epoch: 017 - iter: 01399 - train loss: 2.9671 - time: 0.1359\n","epoch: 017 - iter: 01599 - train loss: 2.9728 - time: 0.1291\n","epoch: 017 - iter: 01799 - train loss: 2.9913 - time: 0.1228\n","epoch: 017 - iter: 01988 - valid loss: 3.0898 - bleu score: 25.0525 - time: 154.6569\n","epoch: 018 - iter: 00199 - train loss: 2.9082 - time: 0.1289\n","epoch: 018 - iter: 00399 - train loss: 2.8587 - time: 0.1271\n","epoch: 018 - iter: 00599 - train loss: 2.9111 - time: 0.1363\n","epoch: 018 - iter: 00799 - train loss: 2.9375 - time: 0.1277\n","epoch: 018 - iter: 00999 - train loss: 2.9201 - time: 0.1319\n","epoch: 018 - iter: 01199 - train loss: 2.9288 - time: 0.1289\n","epoch: 018 - iter: 01399 - train loss: 2.9629 - time: 0.1308\n","epoch: 018 - iter: 01599 - train loss: 2.9427 - time: 0.1315\n","epoch: 018 - iter: 01799 - train loss: 2.9553 - time: 0.1331\n","epoch: 018 - iter: 01988 - valid loss: 3.0941 - bleu score: 26.0171 - time: 158.3021\n","epoch: 019 - iter: 00199 - train loss: 2.8497 - time: 0.1305\n","epoch: 019 - iter: 00399 - train loss: 2.9027 - time: 0.1335\n","epoch: 019 - iter: 00599 - train loss: 2.8741 - time: 0.1261\n","epoch: 019 - iter: 00799 - train loss: 2.9090 - time: 0.1334\n","epoch: 019 - iter: 00999 - train loss: 2.9230 - time: 0.1220\n","epoch: 019 - iter: 01199 - train loss: 2.8967 - time: 0.1307\n","epoch: 019 - iter: 01399 - train loss: 2.9194 - time: 0.1296\n","epoch: 019 - iter: 01599 - train loss: 2.9144 - time: 0.1244\n","epoch: 019 - iter: 01799 - train loss: 2.8934 - time: 0.1282\n","epoch: 019 - iter: 01988 - valid loss: 3.1003 - bleu score: 28.8843 - time: 159.0633\n","epoch: 020 - iter: 00199 - train loss: 2.8337 - time: 0.1281\n","epoch: 020 - iter: 00399 - train loss: 2.8224 - time: 0.1321\n","epoch: 020 - iter: 00599 - train loss: 2.8760 - time: 0.1280\n","epoch: 020 - iter: 00799 - train loss: 2.8596 - time: 0.1308\n","epoch: 020 - iter: 00999 - train loss: 2.8870 - time: 0.1148\n","epoch: 020 - iter: 01199 - train loss: 2.8872 - time: 0.1273\n","epoch: 020 - iter: 01399 - train loss: 2.8842 - time: 0.1311\n","epoch: 020 - iter: 01599 - train loss: 2.8690 - time: 0.1301\n","epoch: 020 - iter: 01799 - train loss: 2.8886 - time: 0.1315\n","epoch: 020 - iter: 01988 - valid loss: 3.0967 - bleu score: 33.6113 - time: 156.9144\n","epoch: 021 - iter: 00199 - train loss: 2.7939 - time: 0.1340\n","epoch: 021 - iter: 00399 - train loss: 2.8350 - time: 0.1317\n","epoch: 021 - iter: 00599 - train loss: 2.8526 - time: 0.1296\n","epoch: 021 - iter: 00799 - train loss: 2.8238 - time: 0.1287\n","epoch: 021 - iter: 00999 - train loss: 2.8610 - time: 0.1328\n","epoch: 021 - iter: 01199 - train loss: 2.8480 - time: 0.1314\n","epoch: 021 - iter: 01399 - train loss: 2.8304 - time: 0.1290\n","epoch: 021 - iter: 01599 - train loss: 2.8675 - time: 0.1283\n","epoch: 021 - iter: 01799 - train loss: 2.8670 - time: 0.1330\n","epoch: 021 - iter: 01988 - valid loss: 3.1122 - bleu score: 33.5113 - time: 152.2195\n","epoch: 022 - iter: 00199 - train loss: 2.7722 - time: 0.1217\n","epoch: 022 - iter: 00399 - train loss: 2.7649 - time: 0.1296\n","epoch: 022 - iter: 00599 - train loss: 2.8013 - time: 0.1323\n","epoch: 022 - iter: 00799 - train loss: 2.8208 - time: 0.1322\n","epoch: 022 - iter: 00999 - train loss: 2.8268 - time: 0.1202\n","epoch: 022 - iter: 01199 - train loss: 2.8360 - time: 0.1323\n","epoch: 022 - iter: 01399 - train loss: 2.8381 - time: 0.1261\n","epoch: 022 - iter: 01599 - train loss: 2.8222 - time: 0.1332\n","epoch: 022 - iter: 01799 - train loss: 2.8508 - time: 0.1221\n","epoch: 022 - iter: 01988 - valid loss: 3.1139 - bleu score: 30.1794 - time: 157.1247\n","epoch: 023 - iter: 00199 - train loss: 2.7552 - time: 0.1234\n","epoch: 023 - iter: 00399 - train loss: 2.7674 - time: 0.1349\n","epoch: 023 - iter: 00599 - train loss: 2.7660 - time: 0.1227\n","epoch: 023 - iter: 00799 - train loss: 2.7907 - time: 0.1319\n","epoch: 023 - iter: 00999 - train loss: 2.7794 - time: 0.1282\n","epoch: 023 - iter: 01199 - train loss: 2.8000 - time: 0.1290\n","epoch: 023 - iter: 01399 - train loss: 2.8148 - time: 0.1277\n","epoch: 023 - iter: 01599 - train loss: 2.8004 - time: 0.1345\n","epoch: 023 - iter: 01799 - train loss: 2.8136 - time: 0.1277\n","epoch: 023 - iter: 01988 - valid loss: 3.1242 - bleu score: 32.3146 - time: 157.4542\n","epoch: 024 - iter: 00199 - train loss: 2.7584 - time: 0.1286\n","epoch: 024 - iter: 00399 - train loss: 2.7669 - time: 0.1317\n","epoch: 024 - iter: 00599 - train loss: 2.7342 - time: 0.1275\n","epoch: 024 - iter: 00799 - train loss: 2.7581 - time: 0.1331\n","epoch: 024 - iter: 00999 - train loss: 2.7345 - time: 0.1318\n","epoch: 024 - iter: 01199 - train loss: 2.7609 - time: 0.1277\n","epoch: 024 - iter: 01399 - train loss: 2.7804 - time: 0.1279\n","epoch: 024 - iter: 01599 - train loss: 2.7812 - time: 0.1215\n","epoch: 024 - iter: 01799 - train loss: 2.7844 - time: 0.1338\n","epoch: 024 - iter: 01988 - valid loss: 3.1298 - bleu score: 30.9548 - time: 158.7421\n","epoch: 025 - iter: 00199 - train loss: 2.7125 - time: 0.1317\n","epoch: 025 - iter: 00399 - train loss: 2.7075 - time: 0.1248\n","epoch: 025 - iter: 00599 - train loss: 2.7665 - time: 0.1258\n","epoch: 025 - iter: 00799 - train loss: 2.7231 - time: 0.1312\n","epoch: 025 - iter: 00999 - train loss: 2.7475 - time: 0.1339\n","epoch: 025 - iter: 01199 - train loss: 2.7395 - time: 0.1308\n","epoch: 025 - iter: 01399 - train loss: 2.7425 - time: 0.1297\n","epoch: 025 - iter: 01599 - train loss: 2.7533 - time: 0.1247\n","epoch: 025 - iter: 01799 - train loss: 2.7696 - time: 0.1270\n","epoch: 025 - iter: 01988 - valid loss: 3.1431 - bleu score: 34.1154 - time: 160.6426\n","epoch: 026 - iter: 00199 - train loss: 2.7031 - time: 0.1317\n","epoch: 026 - iter: 00399 - train loss: 2.6890 - time: 0.1347\n","epoch: 026 - iter: 00599 - train loss: 2.7283 - time: 0.1275\n","epoch: 026 - iter: 00799 - train loss: 2.7224 - time: 0.1326\n","epoch: 026 - iter: 00999 - train loss: 2.7151 - time: 0.1297\n","epoch: 026 - iter: 01199 - train loss: 2.7254 - time: 0.1343\n","epoch: 026 - iter: 01399 - train loss: 2.7160 - time: 0.1253\n","epoch: 026 - iter: 01599 - train loss: 2.7269 - time: 0.1317\n","epoch: 026 - iter: 01799 - train loss: 2.7518 - time: 0.1315\n","epoch: 026 - iter: 01988 - valid loss: 3.1550 - bleu score: 28.5521 - time: 154.7066\n","epoch: 027 - iter: 00199 - train loss: 2.6646 - time: 0.1275\n","epoch: 027 - iter: 00399 - train loss: 2.6844 - time: 0.1307\n","epoch: 027 - iter: 00599 - train loss: 2.6901 - time: 0.1309\n","epoch: 027 - iter: 00799 - train loss: 2.6905 - time: 0.1253\n","epoch: 027 - iter: 00999 - train loss: 2.7062 - time: 0.1323\n","epoch: 027 - iter: 01199 - train loss: 2.6967 - time: 0.1259\n","epoch: 027 - iter: 01399 - train loss: 2.6934 - time: 0.1281\n","epoch: 027 - iter: 01599 - train loss: 2.7075 - time: 0.1331\n","epoch: 027 - iter: 01799 - train loss: 2.7282 - time: 0.1346\n","epoch: 027 - iter: 01988 - valid loss: 3.1609 - bleu score: 32.3788 - time: 160.3106\n","epoch: 028 - iter: 00199 - train loss: 2.6527 - time: 0.1270\n","epoch: 028 - iter: 00399 - train loss: 2.6640 - time: 0.1263\n","epoch: 028 - iter: 00599 - train loss: 2.6624 - time: 0.1227\n","epoch: 028 - iter: 00799 - train loss: 2.6559 - time: 0.1287\n","epoch: 028 - iter: 00999 - train loss: 2.6868 - time: 0.1287\n","epoch: 028 - iter: 01199 - train loss: 2.6944 - time: 0.1226\n","epoch: 028 - iter: 01399 - train loss: 2.6836 - time: 0.1310\n","epoch: 028 - iter: 01599 - train loss: 2.6779 - time: 0.1285\n","epoch: 028 - iter: 01799 - train loss: 2.6920 - time: 0.1296\n","epoch: 028 - iter: 01988 - valid loss: 3.1703 - bleu score: 22.2681 - time: 157.5213\n","epoch: 029 - iter: 00199 - train loss: 2.6229 - time: 0.1314\n","epoch: 029 - iter: 00399 - train loss: 2.6456 - time: 0.1304\n","epoch: 029 - iter: 00599 - train loss: 2.6323 - time: 0.1325\n","epoch: 029 - iter: 00799 - train loss: 2.6265 - time: 0.1327\n","epoch: 029 - iter: 00999 - train loss: 2.6647 - time: 0.1312\n","epoch: 029 - iter: 01199 - train loss: 2.6711 - time: 0.1247\n","epoch: 029 - iter: 01399 - train loss: 2.6773 - time: 0.1348\n","epoch: 029 - iter: 01599 - train loss: 2.6480 - time: 0.1342\n","epoch: 029 - iter: 01799 - train loss: 2.7023 - time: 0.1306\n","epoch: 029 - iter: 01988 - valid loss: 3.1718 - bleu score: 30.5120 - time: 156.8639\n"]}],"source":["import time\n","\n","for epoch in range(opt['epochs']):\n","    total_loss = 0\n","    \n","    for i, batch in enumerate(train_iter): \n","        s = time.time()\n","        loss = step(model, optimizer, batch, criterion)\n","        \n","        total_loss += loss\n","        \n","        if (i + 1) % opt['printevery'] == 0:\n","            avg_loss = total_loss/opt['printevery']\n","            print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f} - time: {:.4f}'.format(epoch, i, avg_loss, time.time()- s))\n","            total_loss = 0\n","\n","    s = time.time()\n","    valid_loss = validiate(model, valid_iter, criterion)\n","    bleuscore = bleu(valid_src_data[:500], valid_trg_data[:500], model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","    print('epoch: {:03d} - iter: {:05d} - valid loss: {:.4f} - bleu score: {:.4f} - time: {:.4f}'.format(epoch, i, valid_loss, bleuscore, time.time() - s))"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T12:12:24.442263Z","iopub.status.busy":"2024-05-18T12:12:24.441908Z","iopub.status.idle":"2024-05-18T12:15:00.912617Z","shell.execute_reply":"2024-05-18T12:15:00.911642Z","shell.execute_reply.started":"2024-05-18T12:12:24.442189Z"},"id":"v5E8G0-8QFbj","trusted":true},"outputs":[{"data":{"text/plain":["30.512013401303328"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["bleu(valid_src_data, valid_trg_data, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T12:15:00.914636Z","iopub.status.busy":"2024-05-18T12:15:00.914261Z","iopub.status.idle":"2024-05-18T12:15:01.165956Z","shell.execute_reply":"2024-05-18T12:15:01.165047Z","shell.execute_reply.started":"2024-05-18T12:15:00.914601Z"},"id":"0CwtdJeUNQJo","trusted":true},"outputs":[{"data":{"text/plain":["'gia đình tôi không nghèo, và bản thân tôi, tôi chưa bao giờ trải qua nạn đói.'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["sentence='My family was not poor , and myself , I had never experienced hunger .'\n","trans_sent = translate_sentence(sentence, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","trans_sent"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T12:15:01.167543Z","iopub.status.busy":"2024-05-18T12:15:01.167151Z","iopub.status.idle":"2024-05-18T12:15:01.171707Z","shell.execute_reply":"2024-05-18T12:15:01.170645Z","shell.execute_reply.started":"2024-05-18T12:15:01.167509Z"},"id":"SuqS-kD90jbQ","trusted":true},"outputs":[],"source":["# model.load_state_dict(torch.load('./transformer.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random\n","\n","en_file_path = '/kaggle/input/phomt-vietnamese-english-machine-translation/PhoMT/tokenization/test/test.en'\n","vi_file_path = '/kaggle/input/phomt-vietnamese-english-machine-translation/PhoMT/tokenization/test/test.vi'\n","\n","test_src_data, test_trg_data = read_data(en_file_path, vi_file_path)\n","\n","sample_size = 10\n","random_indices = random.sample(range(len(test_src_data)), sample_size)\n","test_src_data = [test_src_data[i] for i in random_indices]\n","test_trg_data = [test_trg_data[i] for i in random_indices]\n","\n","df_en = pd.DataFrame({'en': test_src_data})\n","df_vi = pd.DataFrame({'vi': test_trg_data})\n","\n","df_en['num_lines'] = df_en['en'].apply(lambda x: len(str(x).splitlines()))\n","df_vi['num_lines'] = df_vi['vi'].apply(lambda x: len(str(x).splitlines()))\n","merged_df = pd.merge(df_en, df_vi, on='num_lines')\n","\n","for _, row in merged_df.iterrows():\n","    en_sent = row['en']\n","    vi_sent = row['vi']\n","    trans_sent = translate_sentence(en_sent, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","\n","    print(f\"Tiếng Anh: {en_sent}\\nBản dịch: {trans_sent}\\nTiếng Việt (Reference): {vi_sent}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["# Export"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T12:19:48.756090Z","iopub.status.busy":"2024-05-18T12:19:48.755204Z","iopub.status.idle":"2024-05-18T12:19:49.429366Z","shell.execute_reply":"2024-05-18T12:19:49.428485Z","shell.execute_reply.started":"2024-05-18T12:19:48.756054Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"ViEn_transformer.pth\")"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5033109,"sourceId":8446608,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
